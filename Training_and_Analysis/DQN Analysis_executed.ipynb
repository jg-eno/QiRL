{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1a835e7",
   "metadata": {
    "tags": [
     "papermill-error-cell-tag"
    ]
   },
   "source": [
    "<span style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">An Exception was encountered at '<a href=\"#papermill-error-cell\">In [1]</a>'.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5460ae61",
   "metadata": {
    "papermill": {
     "duration": 0.004103,
     "end_time": "2025-11-09T16:31:44.408507",
     "exception": false,
     "start_time": "2025-11-09T16:31:44.404404",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# QiRL: analysis and results \n",
    "\n",
    "In this Notebook you can use the trained quantum agent to analyze its performances and make some nice plots.\n",
    "\n",
    "In particular, here we show how to use the `qasm_simulator` to perform some noisy simulation of the quantum neural network circuit, and show how the number of shots impacts the performances of the quantum agent, Elliot.\n",
    "\n",
    "#### Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f34e6f0a",
   "metadata": {
    "tags": [
     "papermill-error-cell-tag"
    ]
   },
   "source": [
    "<span id=\"papermill-error-cell\" style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">Execution using papermill encountered an exception here and stopped:</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9dbe628",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-09T16:31:44.415939Z",
     "iopub.status.busy": "2025-11-09T16:31:44.415687Z",
     "iopub.status.idle": "2025-11-09T16:31:45.680718Z",
     "shell.execute_reply": "2025-11-09T16:31:45.680091Z"
    },
    "papermill": {
     "duration": 1.269572,
     "end_time": "2025-11-09T16:31:45.681737",
     "exception": true,
     "start_time": "2025-11-09T16:31:44.412165",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'BaseEstimator' from 'qiskit.primitives' (/Users/user/.pyenv/versions/3.12.2/lib/python3.12/site-packages/qiskit/primitives/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Qiskit Machine Learning imports\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mqiskit_machine_learning\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mqkml\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mqiskit_machine_learning\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconnectors\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TorchConnector\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# PyTorch imports\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.2/lib/python3.12/site-packages/qiskit_machine_learning/connectors/__init__.py:32\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# This code is part of a Qiskit project.\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# (C) Copyright IBM 2021, 2024.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# copyright notice, and modified files need to carry a notice indicating\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# that they have been altered from the originals.\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[33;03mConnectors (:mod:`qiskit_machine_learning.connectors`)\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[33;03m======================================================\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     29\u001b[39m \n\u001b[32m     30\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtorch_connector\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TorchConnector\n\u001b[32m     35\u001b[39m __all__ = [\u001b[33m\"\u001b[39m\u001b[33mTorchConnector\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.2/lib/python3.12/site-packages/qiskit_machine_learning/connectors/torch_connector.py:21\u001b[39m\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mqiskit_machine_learning\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01moptionals\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m_optionals\u001b[39;00m\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexceptions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m QiskitMachineLearningError\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mneural_networks\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m NeuralNetwork\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _optionals.HAS_TORCH:\n\u001b[32m     24\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.2/lib/python3.12/site-packages/qiskit_machine_learning/neural_networks/__init__.py:60\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# This code is part of a Qiskit project.\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# (C) Copyright IBM 2019, 2024.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# copyright notice, and modified files need to carry a notice indicating\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# that they have been altered from the originals.\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[33;03mQuantum neural networks (:mod:`qiskit_machine_learning.neural_networks`)\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[33;03m========================================================================\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     57\u001b[39m \u001b[33;03m   LocalEffectiveDimension\u001b[39;00m\n\u001b[32m     58\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m60\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01meffective_dimension\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m EffectiveDimension, LocalEffectiveDimension\n\u001b[32m     61\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mestimator_qnn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m EstimatorQNN\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mneural_network\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m NeuralNetwork\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.2/lib/python3.12/site-packages/qiskit_machine_learning/neural_networks/effective_dimension.py:23\u001b[39m\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m algorithm_globals\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexceptions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m QiskitMachineLearningError\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mestimator_qnn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m EstimatorQNN\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mneural_network\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m NeuralNetwork\n\u001b[32m     26\u001b[39m logger = logging.getLogger(\u001b[34m__name__\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.2/lib/python3.12/site-packages/qiskit_machine_learning/neural_networks/estimator_qnn.py:24\u001b[39m\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mqiskit\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcircuit\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Parameter, QuantumCircuit\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mqiskit\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mprimitives\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BaseEstimatorV2\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mqiskit\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mprimitives\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BaseEstimator, BaseEstimatorV1, Estimator, EstimatorResult\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mqiskit\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mquantum_info\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SparsePauliOp\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mqiskit\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mquantum_info\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01moperators\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbase_operator\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BaseOperator\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'BaseEstimator' from 'qiskit.primitives' (/Users/user/.pyenv/versions/3.12.2/lib/python3.12/site-packages/qiskit/primitives/__init__.py)"
     ]
    }
   ],
   "source": [
    "# General imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Qiskit imports\n",
    "import qiskit as qk\n",
    "\n",
    "# Qiskit Machine Learning imports\n",
    "import qiskit_machine_learning as qkml\n",
    "from qiskit_machine_learning.connectors import TorchConnector\n",
    "\n",
    "# PyTorch imports\n",
    "import torch\n",
    "from torch import Tensor\n",
    "\n",
    "# OpenAI Gym import\n",
    "import gym\n",
    "\n",
    "# Custom Deep Q-Learning code import\n",
    "from dqn_definitions import *\n",
    "\n",
    "# Fix seed for reproducibility\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed);\n",
    "\n",
    "# To get smooth animations on Jupyter Notebooks. \n",
    "import matplotlib as mpl\n",
    "import matplotlib.animation as animation\n",
    "mpl.rc('animation', html='jshtml')\n",
    "\n",
    "def update_scene(num, frames, patch):\n",
    "    patch.set_data(frames[num])\n",
    "    return patch,\n",
    "\n",
    "def plot_animation(frames, repeat=False, interval=40):\n",
    "    fig = plt.figure()\n",
    "    patch = plt.imshow(frames[0])\n",
    "    plt.axis('off')\n",
    "    anim = animation.FuncAnimation(\n",
    "        fig, update_scene, fargs=(frames, patch),\n",
    "        frames=len(frames), repeat=repeat, interval=interval)\n",
    "    plt.close()\n",
    "    return anim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d200174",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "#### Create the Quantum Neural Network circuit\n",
    "\n",
    "First of all, we create the quantum neural network circuit used to train approximate the optimal *state-action values* $Q^\\ast(s, a)$ of the CartPole environment. \n",
    "\n",
    "Let's recall that the state of the CartPole environment is determined by 4 real numbers, thus $s \\in \\mathbb{R}^4$, and that there are only two possilbe actions $a \\in \\{\\text{left}, \\text{right}\\}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ed6225",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Select the number of qubits (one qubit per state variable of the environment)\n",
    "num_qubits = 4\n",
    "\n",
    "# Generate the Parametrized Quantum Circuit (note the reuploading and repetitions flags)\n",
    "qc = parametrized_circuit(num_qubits = num_qubits, \n",
    "                          reuploading = True,\n",
    "                          reps = 6)\n",
    "\n",
    "# Fetch the Parameters from the circuit and divide them in Inputs (X) and Trainable Parameters (params)\n",
    "# The first four parameters are for the inputs\n",
    "X = list(qc.parameters)[: num_qubits]\n",
    "\n",
    "# The remaining ones are the trainable weights of the quantum neural network\n",
    "params = list(qc.parameters)[num_qubits:]\n",
    "\n",
    "qc.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dae4d78",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "#### Interface the QNN with PyTorch  \n",
    "\n",
    "Now that we have defined the parametrized quantum circuit (i.e. the *Quantum Neural Network*), we wrap it inside the `TorchConnector` in order to create the final hybrid quantum-classical `PyTorch` model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1a9a11",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the quantum instance to be used for simulating the quantum circuit\n",
    "qi = QuantumInstance(qk.Aer.get_backend('statevector_simulator'))\n",
    "\n",
    "# Create the QNN from the parametrized quantum circuit defined above\n",
    "qnn = CircuitQNN(qc, input_params=X, weight_params=params, \n",
    "                 quantum_instance = qi)\n",
    "\n",
    "# Interface the QNN with PyTorch\n",
    "initial_weights = (2*np.random.rand(qnn.num_weights) - 1) # <---Initialization weights at random\n",
    "quantum_nn = TorchConnector(qnn, initial_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b157066",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "#### Create the CartPole environment\n",
    "\n",
    "We use OpenAI `gym` to create the CartPole environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e21e2f6",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "env = gym.make(\"CartPole-v1\")\n",
    "input_shape = [4] # == env.observation_space.shape\n",
    "n_outputs = 2 # == env.action_space.n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "826b6d4b",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "#### Classical pre- and post processing layers\n",
    "\n",
    "We instantiate the two classical layers used to pre- and post-process the data, and then stack them together with the quantum model to create the final hybrid quantum-classical neural network. \n",
    "\n",
    "We then load pretrained weights coming from a previous training. Note that the training weights in the file `model_best_weights_6reps_longtrain.pth` are valid for a quantum neural network with 6 repetitions, and using data reuploading. If you wish to use another structure, you need to train the quantum agent from scratch. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e982525d",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Classical trainable preprocessing (encoding) \n",
    "encoding = encoding_layer()\n",
    "\n",
    "# Classical trainable postprocessing\n",
    "exp_val = exp_val_layer()\n",
    "\n",
    "# Stack the classical and quantum layers together \n",
    "model = torch.nn.Sequential(encoding, \n",
    "                            quantum_nn, \n",
    "                            exp_val)\n",
    "\n",
    "# Load pre-trained weights (check if the file exists):\n",
    "try:\n",
    "    model.load_state_dict(torch.load(\"./model_best_weights_6reps_longtrain.pth\"))\n",
    "except: \n",
    "    print(\"No pre-trained weights found. Looks like you have to train from scratch...\")\n",
    "\n",
    "# Print the optimal weights of the agent \n",
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01477fb8",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "Also, note that we upload two other set of weights obtained in other training runs of the quantum agent:\n",
    "* `./model_best_weights_6reps_longtrain`:  succesfull training;\n",
    "* `./model_best_weights_6reps_longtrain2`: training did not converge to the optimal score of 200 in the allowed number of episodes;\n",
    "* `./model_best_weights_6reps_longtrain2_retraing`: succesfull training.\n",
    "\n",
    "You can experiment with these to see the different behaviours learned by the agent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fed36f3",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Unleash the quantum agent\n",
    "\n",
    "You can use the following cell to create an animation of the quantum agent solving the CartPole environment.  \n",
    "> **Note for rendering the animation**  \n",
    "There may be problem running this cell in a Jupyter Notebook, since OpenAI's `env.render` command opens a new window and cause the Notebook's kernel to die if such new window is closed. The suggested solution is to let the new window open but then ignore it, and come back to this Notebook to see the animation generated here (it takes ~10s seconds to output the animation, so don't worry and just wait). Then, only when you are done with this Notebook, you can safely close the external window. Unfortunately, this is a well-known problem of rendering OpenAI animations on a server, and we couldn't find a proper way to circumvent the issue, since it is higlhy dependant on the libraries' versions, as well as on the Operating System."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92940773",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set the environment seed for reproducibility \n",
    "env.seed(42)\n",
    "\n",
    "# 200 is the target score for considering the environment solved\n",
    "max_reward = 200\n",
    "\n",
    "# Run the quantum agent\n",
    "frames = []\n",
    "state = env.reset()\n",
    "for step in range(max_reward):\n",
    "    # Select action\n",
    "    with torch.no_grad():\n",
    "        Q_values = model(Tensor(state)).numpy()\n",
    "    action = np.argmax(Q_values)\n",
    "    \n",
    "    # Perform the action\n",
    "    state, reward, done, info = env.step(action)\n",
    "    if done:\n",
    "        print(\"End at step:\", step)\n",
    "        break\n",
    "    \n",
    "    print(f\"Step {step}, Q-values {Q_values}, Action {action}\", end = \"\\r\")\n",
    "    \n",
    "    img = env.render(mode=\"rgb_array\")\n",
    "    frames.append(img)\n",
    "\n",
    "plot_animation(frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac768294",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Shot noise with `qasm_simulator`  \n",
    "\n",
    "Elliot, the quantum agent, is able to solve the `CartPole` environment when a perfect simulation of the quantum circuit (using the `statevector_simulator`) is run.  \n",
    "\n",
    "But what happens if we run a more realistic simulation, for example including shot noise from stochastic measurement outcomes? We can answer this question by changing `backend` and executing the quantum neural network circuit on the `qasm_simulator`, that simulates the stochastic measurement process, thus introducing shot noise into the simulation.\n",
    "\n",
    "In particular, we are going to investigate how the *number of shots* impacts the performances of the quantum agent. Remember, the higher the numer of shots, the closer the result will be to the ideal (i.e. *noiseless*) result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ebe4d7",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Choose the number of shots used to estimate the expectation values in the QNN circuit\n",
    "n_shots = 1024\n",
    "\n",
    "# Define the quantum instance for the qasm_simulator\n",
    "qi_qasm = QuantumInstance(qk.Aer.get_backend('qasm_simulator'), shots = n_shots)\n",
    "\n",
    "noisy_qnn = CircuitQNN(qc, input_params=X, weight_params=params, \n",
    "                 quantum_instance = qi_qasm)\n",
    "\n",
    "initial_weights = (2*np.random.rand(qnn.num_weights) - 1)\n",
    "noisy_quantum_nn = TorchConnector(noisy_qnn, initial_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89386201",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Exactly as before...\n",
    "encoding = encoding_layer()\n",
    "exp_val = exp_val_layer()\n",
    "\n",
    "noisy_model = torch.nn.Sequential(encoding, \n",
    "                            noisy_quantum_nn, \n",
    "                            exp_val)\n",
    "\n",
    "# Load pre-trained weights:\n",
    "try:\n",
    "    noisy_model.load_state_dict(torch.load(\"./model_best_weights_6reps_longtrain.pth\"))\n",
    "except: \n",
    "    print(\"No pre-trained weights found. Looks like you have to train from scratch...\")\n",
    "\n",
    "noisy_model.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc65545",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "#### Noisy Elliot solves CartPole  \n",
    "\n",
    "We are now ready to run the noisy simulation. Though, since the results are ideed stochastic, is it better to run the code multiple times in order to collect a good statistic and then draw some meaningful conclusions.  \n",
    "\n",
    "For this reason, we let the noisy agent deal with CartPole for multiples episodes, saving the end score of each run. Then, we use these values to evaluate the mean score and the standard deviation.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794c5af3",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "env.seed(42)\n",
    "\n",
    "number_of_episodes = 5 \n",
    "\n",
    "print(f\"Number of shots = {n_shots}\")\n",
    "print(\"-----------------------\")\n",
    "\n",
    "final_step = []\n",
    "for i in range(number_of_episodes):\n",
    "    state = env.reset()\n",
    "    for step in range(200):\n",
    "        print(f\"\\r Episode = {i}, Step = {step}\", end = \"\")\n",
    "        with torch.no_grad():\n",
    "            Q_values = noisy_model(Tensor(state[np.newaxis])).numpy()\n",
    "        action = np.argmax(Q_values[0])\n",
    "\n",
    "        state, reward, done, info = env.step(action)\n",
    "        # print(action, state, model(Tensor([state])))\n",
    "        if done:\n",
    "            print(\", End at step:\", step)\n",
    "            break\n",
    "\n",
    "    final_step.append(step+1)\n",
    "\n",
    "final_steps = np.array(final_step)\n",
    "mean_score = np.mean(final_steps)\n",
    "std_score = np.std(final_steps)\n",
    "print(f\"Mean reward = {mean_score} Â± {std_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd72e62d",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "#### Results\n",
    "\n",
    "You can now run the code above for multiple values of the *number of shots*.  \n",
    "Here you can find the results from previous runs using $100$ episodes for each value of the *number of shots*, in order to have more accurate estimates of the mean final scores and their standard deviations. \n",
    "\n",
    "\n",
    "| Number of Shots | Mean Score | Standard deviation | Number of Episodes  |\n",
    "|---------|------|-----|---------|\n",
    "| 1024 | 115.15 | 49.91 | 100 |\n",
    "| 2048 |  191 | 27.22 | 100 |\n",
    "| 4096 |  195 | 10.90 | 100 |\n",
    "| 8192 |  199.7 | 0.298 | 100 |  \n",
    "\n",
    "We can then use these number for a nice final plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df26895",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_shots = [1024, 2048, 4096, 8192]\n",
    "mean_reward = [115.1, 191, 195, 199.7]\n",
    "std_reward = [49.9, 27.2, 10.9, 0.3]\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_theme()\n",
    "\n",
    "cmap = plt.get_cmap('tab20c')\n",
    "\n",
    "fig = plt.figure(figsize=(8,5))\n",
    "plt.axhline([200], ls = 'dashed', c=cmap(9))\n",
    "plt.text(6000,205, s='Max reward', c=cmap(8))\n",
    "\n",
    "plt.axhline([195], ls = 'dashed', c=cmap(13))\n",
    "plt.text(6000,175, s='Min reward for\\nsolving environment', c=cmap(12))\n",
    "\n",
    "plt.errorbar(num_shots, mean_reward, yerr=std_reward, fmt='o', c = cmap(4), capsize=5, ecolor = cmap(5))\n",
    "plt.ylim([0,230])\n",
    "plt.xticks([1024, 2048, 4096, 8192])\n",
    "plt.xlabel(\"Number of shots\")\n",
    "plt.ylabel(\"Final reward\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "metadata": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2.39893,
   "end_time": "2025-11-09T16:31:46.001767",
   "environment_variables": {},
   "exception": true,
   "input_path": "DQN Analysis.ipynb",
   "output_path": "DQN Analysis_executed.ipynb",
   "parameters": {},
   "start_time": "2025-11-09T16:31:43.602837",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}